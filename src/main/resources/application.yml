server:
  port: 8081
  servlet:
    context-path: /

spring:
  application:
    name: global-mcp-client
  jackson:
    serialization:
      write-dates-as-timestamps: false
    deserialization:
      fail-on-unknown-properties: false
  ai:
    # OpenAI GPT configuration (Primary)
    openai:
      api-key: ${OPENAI_API_KEY:your-openai-api-key-here}
      chat:
        options:
          model: gpt-4o-mini
          temperature: 0.7
          max-tokens: 4096
      enabled: true
    
    # Google Gemini configuration (Secondary)
    google:
      gemini:
        enabled: true
        api-key: ${GEMINI_API_KEY:your-gemini-api-key-here}
        chat:
          options:
            model: gemini-1.5-pro
            temperature: 0.7
            max-tokens: 32000
    
    # Anthropic Claude configuration (Tertiary)
    anthropic:
      claude:
        api-key: ${ANTHROPIC_API_KEY:your-anthropic-api-key-here}
        chat:
          options:
            model: claude-3-5-sonnet-20241022
            temperature: 0.7
            max-tokens: 4096
        enabled: false  # Enable when you have API key
    
    # Local Ollama fallback (Final fallback)
    ollama:
      base-url: "http://localhost:11434"
      chat:
        options:
          model: "llama3.1:8b"
          temperature: 0.7
          max-tokens: 2048
      enabled: true
  web:
    cors:
      allowed-origins: "*"
      allowed-methods: "*"
      allowed-headers: "*"
#  ai:
#    ollama:
#      base-url: "http://localhost:11434"
#      chat:
#        options:
#          model: "llama3.1:8b"
#          temperature: 0.7
#          max-tokens: 2048

logging:
  level:
    com.deepai: DEBUG
    org.springframework.web: WARN
    org.springframework.core.env: DEBUG
    org.springframework.beans.factory.annotation: DEBUG
    root: WARN
  pattern:
    console: "%d{yyyy-MM-dd HH:mm:ss} [%thread] %-5level %logger{36} - %msg%n"

# AI Configuration for custom implementation
ai:
  enabled: true
  provider: openai  # Primary provider (openai, gemini, claude, ollama)
  fallback-providers: ["gemini", "claude", "ollama"]  # Fallback order
  model: gpt-4o-mini
  api-key: ${OPENAI_API_KEY:your-openai-api-key-here}
  
  # Multi-provider model configuration
  models:
    # OpenAI models
    openai:
      default: gpt-4o-mini
      advanced: gpt-4o
      fast: gpt-3.5-turbo
    # Gemini models  
    gemini:
      default: gemini-1.5-pro
      fast: gemini-1.5-flash
      reasoning: gemini-1.5-pro
    # Claude models
    claude:
      default: claude-3-5-sonnet-20241022
      fast: claude-3-haiku-20240307
      advanced: claude-3-opus-20240229
    # Ollama models
    ollama:
      default: llama3.1:8b
      code: deepseek-coder:6.7b
      fast: phi3:mini

management:
  endpoints:
    web:
      exposure:
        include: health,info,metrics,prometheus
  endpoint:
    health:
      show-details: always
  prometheus:
    metrics:
      export:
        enabled: true

mcp:
  client:
    default-timeout: 5000
    retry:
      max-attempts: 2
      backoff-multiplier: 1.2
  servers:
    oracle-mcp-server:
      type: stdio
      command: "java"
      args:
        - "-Dlogging.level.root=ERROR"
        - "-Dlogging.level.com.oracle.mcp=ERROR"
        - "-Dspring.main.banner-mode=off"
        - "-Dspring.output.ansi.enabled=never"
        - "-Djava.awt.headless=true"
        - "-jar"
        - 'G:\\Software G\\MCP\\mcp-oracledb-server\\target\\mcp-oracledb-server-1.0.0-PRODUCTION.jar'
        - "--spring.profiles.active=mcp-run"
        - "--logging.level.root=ERROR"
        - "--logging.pattern.console="
        - "--spring.main.banner-mode=off"
      timeout: 20000
      enabled: true
      environment:
        ORACLE_DB_URL: "jdbc:oracle:thin:@localhost:1521:XE"
        ORACLE_DB_USER: "C##loan_schema"
        ORACLE_DB_PASSWORD: "loan_data"
        ORACLE_HOST: "localhost"
        ORACLE_PORT: "1521"
        ORACLE_SID: "XE"
        MCP_TOOLS_EXPOSURE: "all"
        ENTERPRISE_ENABLED: "true"
        SPRING_MAIN_BANNER_MODE: "off"
        LOGGING_LEVEL_ROOT: "ERROR"

---
# Server profile - disable MCP servers for REST API testing
spring:
  config:
    activate:
      on-profile: server

mcp:
  servers: {}
#    filesystem-python-mcp-server:
#      type: stdio
#      command: "D:\\MCP\\MCP-workspace-bootcampToProd\\filesystem_mcp_server\\venv\\Scripts\\python.exe"
#      args:
#        - "D:\\MCP\\MCP-workspace-bootcampToProd\\filesystem_mcp_server\\src\\main.py"
#      timeout: 8000
#      enabled: true
